<style>
table, th, td {
  text-align: center;
}
</style>
<h3>Tutorials and invited talks</h3>
<ul class="list-group">
  <li class="list-group-item publist_row">
      <span class="list-group-item-text" ng-click="showMoreEMIM20tut = !showMoreEMIM20tut" >
          <i class="material-icons">record_voice_over</i><!--<i class="material-icons">duo</i>-->
          <i class="material-icons">group_add</i>
          Pol del Aguila Pla, <strong> ES 02 -- Biomedical imaging as an inverse problem, </strong>
          <em>[EMIM20] , </em> Thessaloniki, Greece (Virtual conference), August 2020
          <i id="morearrow" class="material-icons color-theme">
              {{showMoreEMIM20tut ? 'arrow_downward' : 'arrow_forward'}}
          </i> </a>
      </span>
      <div ng-show="showMoreEMIM20tut">
          <p style="text-align:justify"> <strong>Abstract:</strong> The impact of biomedical imaging has increased steadily over the past four decades. Part of this is due to the improvement of reconstruction methods, which have provided increasing image quality and resolution. In this tutorial, we present a well-structured view of the field of biomedical image reconstruction based on the few basic building blocks of any imaging system and the three generations of available methods, i.e., classical, sparsity-based, and deep neural networks techniques. For any given imaging problem, attendants will learn to quickly identify its fundamental building blocks from an inverse-problems perspective and propose adequate methodology. Furthermore, we will introduce how to obtain fast prototypes of reconstruction techniques using GlobalBioIm, an efficient MATLAB library tailored to image reconstruction problems.
          <!--
          <video width="90%" controls poster="data/talks/StillBanner_ICASSP2020Tutorial.png">
          <source src="https://videoieeetv.s3.amazonaws.com/ns/ieeetvdl/2020/ICASSP/01_ICASSP%20finalized%20videos/T-10_P1_Tutorial_Biomedical_Imaging_Reconstruction_new.mp4"  type="video/mp4" >
          Your browser does not support the HTML5 video tag, you can find the video of this talk hosted
          at the <a href="https://videoieeetv.s3.amazonaws.com/ns/ieeetvdl/2020/ICASSP/01_ICASSP%20finalized%20videos/T-10_P1_Tutorial_Biomedical_Imaging_Reconstruction_new.mp4">IEEE TV</a>.
          </video>
          -->
          <div id="pubButtons">
              <a class="label label-theme" href="data/talks/EMIM2020.pdf">Slides</a>
          </div>
      </div>
  </li>
    <li class="list-group-item publist_row">
        <span class="list-group-item-text" ng-click="showMoreICASSP20tut = !showMoreICASSP20tut" >
            <i class="material-icons">record_voice_over</i><i class="material-icons">duo</i><i class="material-icons">group_add</i>
            Michaël Unser and Pol del Aguila Pla, <strong> Tutorial 10: Biomedical Image Reconstruction—From Foundations To Deep Neural Networks, </strong>
            <em>[ICASSP20] IEEE International Conference on Acoustics, Speech and Signal Processing, </em> Barcelona, Catalonia (Virtual conference), May 2020
            <i id="morearrow" class="material-icons color-theme">
                {{showMoreICASSP20tut ? 'arrow_downward' : 'arrow_forward'}}
            </i> </a>
        </span>
        <div ng-show="showMoreICASSP20tut">
            <p style="text-align:justify"> <strong>Abstract:</strong> Biomedical imaging plays a key role in medicine and biology. Its range of applications and its impact in research and medical practice have increased steadily during the past 4 decades. Part of the astonishing improvements in image quality and resolution is due to the use of increasingly sophisticated signal-processing techniques. This, in itself, would justify the tutorial. Nonetheless, the field is now transitioning towards the deep-learning era, where disruptive improvements and lack of theoretical background go hand-in-hand. To harness the power of these new techniques without suffering from their pitfalls, a structured understanding of the field is fundamental.</p>

            <p style="text-align:justify"> We start the tutorial by presenting the building blocks of an image-reconstruction problem, from the underlying image that lives in function spaces to its observed discrete measurements. Most importantly, we detail the small collection of forward and sampling operators that allow one to model most biomedical imaging problems, including magnetic resonance imaging, bright-field microscopy, structured-illumination microscopy, x-ray computed tomography, and optical diffraction tomography. This leads up to our exposition of 1st-generation methods (e.g., filtered back-projection, Tikhonov regularization), the regimes in which they are most attractive, and how to implement them efficiently. </p>

            <p style="text-align:justify"> We then transition to 2nd-generation methods (non-quadratic regularization, sparsity, and compressive sensing) and show how advanced signal processing allows image reconstruction with smaller acquisition times, less invasive procedures, and lower radioactive and irradiation dosage. We expose the foundations of these methods (results in compressed-sensing recovery, representer theorems, infinite-divisible distributions) and the most useful algorithms in imaging (proximal operators, projected gradient descent, alternate-direction method of multipliers), again exemplifying their efficient implementation.</p>

            <p style="text-align:justify"> Finally, we present the state of the art in 3rd-generation methods (deep-learning reconstruction of images), categorizing them using the building-block terminology introduced throughout the tutorial. In this manner, we emphasize the links to 1st- and 2nd-generation methods in order to provide intuition and guidelines to devise and understand novel 3rd-generation methods. Furthermore, we state the benefits of each proposal and give cautionary examples of the dangers of overreliance on training data. </p>

            <table style="width:100%">
            <tr>
                <th>Parts I and II</th>
                <th>Part III (my part is here)</th>
                <th>Part IV</th>
            </tr>
            <tr>
                <td><video width="90%" controls poster="data/talks/StillBanner_ICASSP2020Tutorial.png">
                <source src="https://videoieeetv.s3.amazonaws.com/ns/ieeetvdl/2020/ICASSP/01_ICASSP%20finalized%20videos/T-10_P1_Tutorial_Biomedical_Imaging_Reconstruction_new.mp4"  type="video/mp4" >
                Your browser does not support the HTML5 video tag, you can find the video of this talk hosted
                at the <a href="https://videoieeetv.s3.amazonaws.com/ns/ieeetvdl/2020/ICASSP/01_ICASSP%20finalized%20videos/T-10_P1_Tutorial_Biomedical_Imaging_Reconstruction_new.mp4">IEEE TV</a>.
            </video></td>
                <td><video width="90%" controls poster="data/talks/StillBanner_ICASSP2020Tutorial.png">
                <source src="https://videoieeetv.s3.amazonaws.com/ns/ieeetvdl/2020/ICASSP/01_ICASSP%20finalized%20videos/T-10_P2_Tutorial_Biomedical_Imaging_Reconstruction.mp4"  type="video/mp4" >
                Your browser does not support the HTML5 video tag, you can find the video of this talk hosted
                at the <a href="https://videoieeetv.s3.amazonaws.com/ns/ieeetvdl/2020/ICASSP/01_ICASSP%20finalized%20videos/T-10_P1_Tutorial_Biomedical_Imaging_Reconstruction_new.mp4">IEEE TV</a>.
            </video></td>
                <td><video width="90%" controls poster="data/talks/StillBanner_ICASSP2020Tutorial.png">
                <source src="https://videoieeetv.s3.amazonaws.com/ns/ieeetvdl/2020/ICASSP/01_ICASSP%20finalized%20videos/T-10_P3_Tutorial_Biomedical_Imaging_Reconstruction.mp4"  type="video/mp4" >
                Your browser does not support the HTML5 video tag, you can find the video of this talk hosted
                at the <a href="https://videoieeetv.s3.amazonaws.com/ns/ieeetvdl/2020/ICASSP/01_ICASSP%20finalized%20videos/T-10_P1_Tutorial_Biomedical_Imaging_Reconstruction_new.mp4">IEEE TV</a>.
            </video></td>
            </tr>
            </table>

            <div id="pubButtons">
                <a class="label label-theme" href="data/talks/ICASSP2020_Slides_TutorialBiomedicalImageReconstruction.pdf">Slides</a>
                <a class="label label-theme" href="data/talks/Implementation_example.zip">Code</a>
            </div>
        </div>
    </li>
</ul>

<h3>Talks at international research events</h3>
<ul class="list-group">
    <li class="list-group-item publist_row">
        <span class="list-group-item-text" ng-click="showMoreICASSP20 = !showMoreICASSP20" >
            <i class="material-icons">record_voice_over</i><i class="material-icons">duo</i>
            Pol del Aguila Pla, <strong> Clock synchronization over networks using sawtooth models, </strong>
            <em>[ICASSP20] IEEE International Conference on Acoustics, Speech and Signal Processing, </em> Barcelona, Catalonia (Virtual conference), May 2020
            <i id="morearrow" class="material-icons color-theme">
                {{showMoreISCASSP20 ? 'arrow_downward' : 'arrow_forward'}}
            </i> </a>
        </span>
        <div ng-show="showMoreICASSP20">
            <p style="text-align:justify"> <strong>Abstract:</strong> Clock synchronization and ranging over a wireless network with low communication overhead is a challenging goal with tremendous impact. In this paper, we study the use of time-to-digital converters in wireless sensors, which provides clock synchronization and ranging at negligible communication overhead through a sawtooth signal model for round trip times. In particular, we derive Cramér-Rao lower bounds for a linearitzation of the sawtooth signal model, and we thoroughly evaluate simple estimation techniques by simulation, giving clear and concise performance references for this technology. </p>

            <iframe src="https://drive.google.com/file/d/15J7LlN8-fBk1ZA3AmxMW_ku3LY-4o7vu/preview" width="100%" height="480"></iframe>
            <div id="pubButtons">
                <a class="label label-theme" href="data/talks/Slides_ICASSP2020.pdf">Slides</a>
            </div>

        </div>
    </li>
    <li class="list-group-item publist_row">
        <span class="list-group-item-text" ng-click="showMoreISBI19 = !showMoreISBI19" >
            <i class="material-icons">record_voice_over</i>
            Pol del Aguila Pla, <strong> SpotNet – Learned iterations for cell detection in image-based immunoassays, </strong>
            <em>[ISBI19] IEEE International Symposium on Biomedical Imaging, </em> Venice, Italy, April 2019
            <i id="morearrow" class="material-icons color-theme">
                {{showMoreISBI19 ? 'arrow_downward' : 'arrow_forward'}}
            </i> </a>
        </span>
        <div ng-show="showMoreISBI19">
            <p style="text-align:justify"> <strong>Abstract:</strong> Accurate cell detection and counting in the image-based ELISpot and FluoroSpot immunoassays is a challenging task. Methodology recently proposed by our group matches human accuracy by leveraging knowledge of the underlying physical process of these assays and using state-of-the-art iterative techniques to solve an inverse problem. Nonetheless, thousands of computationally expensive iterations are often needed to reach a near-optimal solution. In this paper, we exploit the structure of the iterations to design a parameterized computation graph, <i>SpotNet</i>, that learns the characteristic patterns embedded within several training images and their respective cell secretion information. Further, we compare SpotNet to a customized convolutional neural network layout for cell detection based on recent advances. We show empirical evidence that, while both designs obtain a detection performance far beyond that of a human expert, SpotNet is substantially easier to train and obtains better estimates of cell secretion. </p>

            <div id="pubButtons">
                <a class="label label-theme" href="data/talks/SpotNet_learned_iterations_cell_detection_immunoassays.pdf">Slides</a>
            </div>
        </div>
    </li>
    <li class="list-group-item publist_row">
        <span class="list-group-item-text" ng-click="showMoreu = !showMoreu" >
            <i class="material-icons">view_carousel</i>
            Pol del Aguila Pla, <strong> Source localization by spatially variant blind deconvolution, </strong>
            <em>[SIAM IS18] SIAM Conference on Imaging Science, </em> Bologna, Italy, June 2018
            <i id="morearrow" class="material-icons color-theme">
                {{showMoreu ? 'arrow_downward' : 'arrow_forward'}}
            </i> </a>
        </span>
        <div ng-show="showMoreu">
            <p style="text-align:justify"> <strong>Abstract:</strong> In this poster, I will present an inverse problem framework to detect point and extended sources in scientific imaging. With clear applications in biology, medical sciences and astronomy, among others, our proposal is a blind deconvolution approach that allows for spatially variant point spread functions. The methodology builds on the extensive research in convolutional coding in deep learning and signal processing, and introduces group-sparsity constraints to this context. </p>

            <div id="pubButtons">
                <a class="label label-theme" href="https://www.siam-is18.dm.unibo.it/uploads/store/a7a8b242b168225d0be8998fa373f58b.pdf">Poster</a>
            </div>
        </div>
    </li>
     <li class="list-group-item publist_row">
        <span class="list-group-item-text" ng-click="showMore0 = !showMore0" >
            <i class="material-icons">view_carousel</i>
            Pol del Aguila Pla, <strong> Convolutional group-sparse coding and source localization, </strong>
            <em>[ICASSP2018] IEEE International Conference on Acoustics, Speech and Signal Processing, </em> Calgary, Alberta, Canada, April 2018
            <i id="morearrow" class="material-icons color-theme">
                {{showMore0 ? 'arrow_downward' : 'arrow_forward'}}
            </i> </a>
        </span>
        <div ng-show="showMore0">
            <p style="text-align:justify"> <strong>Abstract:</strong> In this paper, we present a new interpretation of non-negatively constrained convolutional coding problems as blind deconvolution problems with spatially variant point spread function. In this light, we propose an optimization framework that generalizes our previous work on non-negative group sparsity for convolutional models. We then link these concepts to source localization problems that arise in scientific imaging, and provide a visual example on an image derived from data captured by the Hubble telescope.</p>

            <div id="pubButtons">
                <a class="label label-theme" href="data/talks/Poster_ICASSP2018.pdf">Poster</a>
            </div>
        </div>
    </li>
    <li class="list-group-item publist_row">
        <span class="list-group-item-text" ng-click="showMore1 = !showMore1" >
            <i class="material-icons">view_carousel</i>
            Pol del Aguila Pla, <strong> Cell detection in image-based immunoassays, </strong>
            <em>[ISBI18] IEEE International Symposium on Biomedical Imaging, </em> Washington DC, USA, April 2018
            <i id="morearrow" class="material-icons color-theme">
                {{showMore1 ? 'arrow_downward' : 'arrow_forward'}}
            </i> </a>
        </span>
        <div ng-show="showMore1">
            <p style="text-align:justify"> <strong>Abstract:</strong> Cell detection and counting in the image-based ELISPOT and Fluorospot immunoassays is considered a bottleneck. The task has remained hard to automatize, and biomedical researchers often have to rely on results that are not accurate. Previously proposed solutions are heuristic, and data-based solutions are subject to a lack of objective ground truth data. In this paper, we analyze a partial differential equations model for ELISPOT, Fluorospot, and assays of similar design. This leads us to a mathematical observation model for the images generated by these assays. We use this model to motivate a methodology for cell detection. Finally, we provide a real-data example that suggests that this cell detection methodology and a human expert perform comparably.</p>

            <div id="pubButtons">
                <a class="label label-theme" href="data/talks/Poster_ISBI2018.pdf">Poster</a>
            </div>
        </div>
    </li>
    <li class="list-group-item publist_row">
        <span class="list-group-item-text" ng-click="showMore2 = !showMore2" >
            <i class="material-icons">record_voice_over</i><i class="material-icons">duo</i>
            Pol del Aguila Pla, <strong> Cell detection by functional inverse diffusion and group sparsity, </strong>
            <em>[VMVW02] Workshop on Generative models, parameter learning and sparsity, </em> Isaac Newton Institute for Mathematical Sciences, University of Cambridge, UK, November 2017
            <i id="morearrow" class="material-icons color-theme">
                {{showMore2 ? 'arrow_downward' : 'arrow_forward'}}
            </i> </a>
        </span>
        <div ng-show="showMore2">
            <p style="text-align:justify"> <strong>Abstract:</strong> Biological assays in which particles generated by cells bind to a surface and can be imaged to reveal the cells' location are ubiquitous in biochemical, pharmacological and medical research. In this talk, I will describe the physics of these processes, a 3D radiation-diffusion-adsorption-desorption partial differential equation, and present our novel parametrization of its solution (i.e., the observation model) in terms of convolutional operators. Then, I will present our proposal to invert this observation model through a functional optimization problem with group-sparsity regularization and explain the reasoning behind this choice of regularizer. I will also present the results needed to derive the accelerated proximal gradient algorithm for this problem, and justify why we chose to formulate the algorithm in the original function spaces where our observation model operates. Finally, I will briefly comment on our choice of discretization, and show the final performance of our algorithm in both synthetic and real data.</p>

            <video width="100%" controls poster="data/talks/StillBanner_IsaacNewtonTalk.png">
                <source src="https://downloads.sms.cam.ac.uk/2600830/2600858.mp4"  type="video/mp4" >
                <source src="https://downloads.sms.cam.ac.uk/2600830/2600833.mp4"  type="video/mp4" >
                <source src="https://downloads.sms.cam.ac.uk/2600830/2600834.webm" type="video/webm">
                Your browser does not support the HTML5 video tag, you can find the video of this talk hosted
                at the Isaac Newton Institute for Mathematical Sciences' <a href="http://bit.ly/Pol-IsaacNewton-VMVW02">website</a>.
            </video>
            <div id="pubButtons">
                <a class="label label-theme" href="data/talks/Cell_detection_by_functional_inverse_diffusion_and_group_sparsity.pdf">Slides</a>
                <a class="label label-theme" href="data/talks/Video_Particles.rar">Video of simulated particles</a>
                <a class="label label-theme" href="data/talks/Poster_IsaacNewton2017.pdf">Poster</a>
            </div>
        </div>
    </li>
</ul>
